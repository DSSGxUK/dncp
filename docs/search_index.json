[["index.html", "DNCP Project Documentation 1 Introduction 1.1 Motivation 1.2 Objectives &amp; Final Product", " DNCP Project Documentation Fellows: Beck DeYoung, Maria-Cristiana Girjau, Dushant Gohri, Ethan Lee Techical Mentor: Robert Hager Project Manager: Daniel Townsend 25 August 2021 1 Introduction 1.1 Motivation Our original motivation for this project lies in the work of the Paraguayan Department of Public Contracting (DNCP). The DNCP manages the public procurement process in Paraguay, through which goods and services are purchased by governments and state-owned institutions. The types of these goods and services vary immensely, ranging from automobile parts to electrical power systems. As a result, one of the DNCP’s responsibilities is to look past the diverse item categories and ensure that all items are purchased at a fair price; if any purchases seem suspicious, the DNCP is able to launch investigations into them. Despite its best efforts, the DNCP can find itself in situations where precious time and effort is spent towards investigating items that ultimately were purchased through a lawful and fair procedure. Additionally, there is a chance that the DNCP misses an item that should have been investigated due to the sheer number of tenders that are processed through the public procurement process each year. Thus, this project aims to assist the DNCP in its efforts to coordinate public procurement in a fair manner by creating a model that estimates the prices of items involved in public procurement. Accomplishing this may help the DNCP to preserve time and resources by more easily identifying suspicious purchases and anomalies. 1.2 Objectives &amp; Final Product The primary objective of this project is to predict the unit prices of goods and services involved in the public procurement process. Additionally, there are some subgoals of this project that were implemented. First, we sought to create an automated exploratory data analysis of any input dataset containing information on goods and services, so that a user could easily analyze the distributions and summary statistics of all items involved in a tender or group of tenders. Second, we wished to automate an effective feature engineering process on new input datasets, such that the data would be manipulated appropriately and new grouping variables representing the contexts of items would be added. Lastly, we wished to train an accurate model that would output predictions for the unit prices of items based on previously collected information. The final product of this project is a fully trained model that very closely approximates the unit prices of items (median RMSE \\(&lt;9\\) USD). Additionally, we have created an automated pipeline for feature engineering, EDA on new datasets, model training, and predictions on new datasets. "],["fe.html", "2 Feature Engineering 2.1 The Script 2.2 The Configuration File", " 2 Feature Engineering 2.1 The Script The feature engineering script, fe.R, performs a multitude of tasks to clean and prepare the input data for the tender and procurement process. 2.1.1 Required Files The fe.R script is not a self contained script and requires the input data and other scripts containing helper functions. The following is a list of necessary files and the structure they should follow. Make sure the folders are already created in the directory before running the scripts: src/ scripts/ fe.R (encompassing script to run) functions/ fe_helpers.R (set of helper functions to perform tasks in fe.R) fe_group_buyer.R (script to create buyer groups) fe_group_context.R (script to create context groups) fe_outlier_detection.R (script to detect outliers) data/ raw/ ipc.csv (dataset with consumer price index data) cotizacion.csv (dataset with USD to PYG exchange rates) Any other input data to be included in the training dataset conf/ fe_conf.yaml (configuration file for fe.R) eda_conf.yaml (configuration file for automated EDA) meta/ training_set_data_dict_VERSION.xlsx (data dictionary) reports/ training_set_eda.Rmd (file to perform automated EDA on the training dataset) 2.1.2 Required R Packages The following is a list of R packages necessary for running fe.R and its associated scripts and reports: caret cowplot janitor lubridate moments tidytext tidyverse tm wesanderson yaml 2.1.3 Tasks Performed 2.1.3.1 Joining the Data To perform an analysis on the database, a single dataset is necessary. Thus, after loading in all desired input data, they are merged together. How to specify desired input data is explained in the Configuration Data Loading section. To merge them together, a few steps are necessary. The two most important are to rename the individual id columns to enable merging. For example, producto_n1 has an id column and producto_n2 has an producto_n1_id column which are clearly related. The script will rename id to be producto_n1_id and thus easily allow for merging. The second important step is to rename all variables to include information about the original input data. As multiple datasets have the same variable names, it is necessary to make this distinction for clarity and data provenance. For example, monto_total is present in both pac and llamado. In the joined dataset, there are two columns, monto_total_pac and monto_total_llamado. Once this task is complete, there is a single unified dataset with all variables from the desired input data 2.1.3.2 Creating Goods/Services Indicator The level 5 (producto_n5) product descriptions contains the variable codigo, representing a unique code for each product in the product catalog. The catalog contains both goods and services, with goods being the products with codes below 700000, and services above 700000. We utilized this variable to create a new variable, service, that indicates whether a given product is a good or a service, with the value TRUE if a product is a service, or FALSE if it is a good. This variable can be used as a predictor, or as a way to create a model that focuses on either goods or services and not both. 2.1.3.3 Filtering The merged dataset can then be filtered down to a desired level. Unlimited conditions can be added to the configuration file using the instructions in Configuration Filtering section. Some examples of desirable filter conditions are removing open contracts, choosing data after 2015, or removing services. 2.1.3.4 Adjusting for Currency and Inflation The prices for the contracts are not uniform throughout the data. Inflation and deflation of currency impacts direct comparability of prices for different years. Additionally, some prices are presented in US dollars instead of PYG. To enable consistency in prices, we performed two tasks. First, all USD prices are converted into PYG for their given year using the daily conversion rates in cotizacion.csv. Then, the PYG prices are adjusted to their true value in a desired year and month using consumer price index (CPI) data from the Central Bank of Paraguay. In brief, the CPI accounts for inflation by measuring average changes in prices over time that consumers pay for goods and services. The base year will be given a value of 100, and every other year is assigned a value below or above 100 based on these changes in prices. The script allows for a dynamic selection of a base year and base month for inflation adjustment. This means prices can be adjusted to be in March 2021 PYG or June 2015 PYG, etc. Performing this selection is described in the Configuration Inflation section. 2.1.3.5 Creating Grouping Variables To enhance the training dataset, two new categories of indicator variables were created using text analysis: buyer groups and context groups. Buyer group variables are created through text analysis on the buyer names for each tender, as recorded in the descripcion field of unidad_contratacion.csv. Each buyer group variable is associated to a specific string pattern: String Pattern police policia hospital hospital|cancer science ciencia health salud law justicia|judicial ministry ministerio education universidad|facultad|educacion army defensa|comando|armada|ejercito bank banco tech tecnologia|aeronautica electricity ande|electricidad The education buyer variable will then be true for all items in a specific tender if the name of that tender’s buyer includes any of the words “universidad”, “facultad”, or “educacion”. Similarly, context group variables are created through text analysis on the tender descriptions, as recorded in the detalle field of llamado.csv. Each context group variable is once agai associated to a specific string pattern: String Pattern food alimento|alimenticio vehicle vehiculo construction construccion|edificio|obra hardware ferreteria|herramienta preventive_corrective preventivo|correctivo real_estate inmuebl office oficina|tinta|toner|papel|fotocopiadora|impreso|impresion specialized_supplies insumo cleaning limpieza politics electoral|justicia medical hospital|medicamento|medico chemical reactivo|laboratorio|quimico|quimica insurance seguro specific_brand marca electricity electric kitchen cocina|comedor|gastronomic computer informatico|computadora air_conditioning aire|acondicionado spare_part respuesto machine maquinaria fuel combustible|diesel More information about the buyer grouping process and the context grouping process can be found in the Buyer Grouping section and the Context Grouping section respectively. 2.1.3.6 Selecting Target and Predictors Only the desired target variables and predictors variables are selected from the training dataset to reduce memory usage. 2.1.3.7 Log-Transforming Skewed Variables There are usually two reasons to log-transform variables. The first is when the distribution of the target variable is skewed. It is ideal to have a normally distributed target variable, so a transformation is desired, which is in this case, a log base 10 transformation. For prices, a log transformation is common in analyses. The second reason is that a given predictor appears to be logarithmically related to the target variable, which can be determined from correlation plots. Then, the predictor is transformed. 2.1.3.8 Removing Outliers Really high outliers in terms of unit price are removed, since they may skew the model and make it inaccurate for more reasonable prices. To identify these outliers, an isolation forest was used, since it is one of the most scalable anomaly detection algorithms. The isolation forest assigns an anomaly score to each observation, ranging from 0 to 1 (with 0 being less anomalous and 1 very anomalous). Outliers were defined as having an anomaly score higher than 0.6 (value that can be customized in fe_conf.yaml), so all observations with an anomaly score higher than 0.6 were removed. More information about the outlier detection and removal process can be found in the Outlier Removal section. 2.1.3.9 Merging Sparse Categories To facilitate prediction, uncommon values in categorical variables are grouped together into an Other group. For example, say a given categorical variable has six options: A, B, C, D, E, and F. The categories have 100, 200, 300, 200, 2, and 5 observations respectively. In this case, We would alter the variable to have 5 categories: A, B, C, D, and Other, where Other is comprised of the 2 and 5 observations from E and F. The threshold for determining what proportion of samples is too sparse can be easily changed in the configuration file. 2.1.3.10 One-Hot Encoding Categorical Variables Many machine learning algorithms do not support categorical/text inputs. So it is necessary to convert all categorical predictors to numerical data. This is accomplished through one-hot encoding, which creates a new variable for each category. For example, say a given categorical variable called “Cat” has three options: A, B, and C. One-hot encoding will create the three columns Cat_A, Cat_B, and Cat_C. Each column has two possible values: 1 if a given observation is in the category, or 0 if it is not. So an observation in category B, will have values 0, 1, 0 for the respective new columns. The model generated in order to create these new variables is stored, and should be used to reconstruct the one-hot encoding for future test datasets to guarantee the column specifications are the same. 2.1.3.11 Imputing/Removing Missing Values In any dataset/database, there are going to be missing values for certain variables. As many machine learning algorithms do not allow missing values, these need to be removed or imputed. For the target variable, we do not want to make assumptions about values, so all rows where the target variable has a missing value are removed. For TRUE/FALSE predictor variables, missing values were imputed to be FALSE. For categorical variables, all missing entries in one-hot encoded columns are set to 0, indicating that the value is none of those categories. Currently, we do not have any numeric variables with missing values, so if they should be included in the future, imputation methods need to be implemented. 2.1.3.12 Running Automated Exploratory Data Analysis The fe.R script saves the training dataset before one-hot encoding, and inputs it into the automated exploratory data analysis file. A more in-depth look at the output can be found in the Exploratory Data Analysis section. 2.1.4 Outputs The following are the outputs produced by running fe.R and the associated scripts and reports. Make sure these folders are already created in the directory before running the scripts. reports/ training_set_eda_DATE.pdf (report generated by the automated EDA) data/ output/ training_set_DATE.rds (training dataset generated from the script) one_hot_encoding_DATE.rds (one-hot encoding model) 2.2 The Configuration File The configuration file fe_conf.yaml contains the inputs for the tasks outlined in Feature Engineering. This file needs to be altered for any desired change of input. The following sections describe how to make those alterations. Every value must be stored in quotation marks unless it is a number or boolean (TRUE/FALSE). 2.2.1 Loading in Data To load in the correct input data, the individual files must all be in the same directory, with the path location specified under loc:. Importantly, when the individual files are listed under input_data:, they must be in order of joining. The script will merge each input data file with the one listed prior, so there must be an id column relating the two. Below is the list of input data files that we have identified as the most useful; they are in correct merging order. data: loc: &quot;/files/data/&quot; # loc is input path dest: &#39;~/dncp/data/output/&#39; # dest is output path input_data: # listed in order of joining item_solicitado: &#39;item_solicitado.csv&#39; llamado_grupo: &#39;llamado_grupo.csv&#39; llamado: &#39;llamado.csv&#39; pac: &#39;pac.csv&#39; producto_n5: &#39;producto_n5.csv&#39; producto_n4: &#39;producto_n4.csv&#39; producto_n3: &#39;producto_n3.csv&#39; producto_n2: &#39;producto_n2.csv&#39; producto_n1: &#39;producto_n1.csv&#39; unidad_contratacion: &#39;unidad_contratacion.csv&#39; entidad: &#39;entidad.csv&#39; nivel_entidad: &#39;nivel_entidad.csv&#39; The naming of each dataset is important as well. Using pac as an example, the following snippet explains the nomenclature of the configuration file for loading in the data. pac: &#39;pac.csv&#39; # pac: is the name of the data file which will be attached to every # variable name in the file, as in monto_total_pac # # &#39;pac.csv&#39; is the filename holding the input data 2.2.2 Features 2.2.2.1 Selecting Features Under the feature: section, the desired target variable and predictor variables should be specified as a single string and list of strings respectively. The fe.R script will rename all variables to be of the form variable_dataset, explained in the Joining Data. In the configuration file, this naming conventions should be used at all locations. Additionally, a unique id column should be specified to maintain data provenance. For this training dataset, it is most commonly the id column in item solicitado: item_solicitado_id. 2.2.2.2 Specifying Groups for New Variable Creation Almost all of the grouping section of the configuration file should not be touched. The names have been determined through text analysis (as explained in the Creating Grouping Variables section) and do not require alterations. The parts that can be changed are the use: section under each group. This value indicates whether or not the given group variable should be including in the dataset or not. If set to false, then the given group will not be created and vice versa for if set to true. groups: buyer: use: true # this line can be changed 2.2.2.3 Filtering To add filter conditions, add logical statements (i.e., ones that can be evaluated to be TRUE or FALSE) in quotations to the filter: section. If no conditions are desired, this section can be left blank. Unlimited conditions can be added in the same format as the examples below. filter: # the level 2 product description is &quot;Fuels&quot; condition_1: &#39;descripcion_ingles_producto_n2 == &quot;Fuels&quot;&#39; # the price is above 10,000 PYG condition_2: &#39;precio_unitario_item_solicitado &gt; 10000&#39; # the publication year is after 2015 condition_3: &#39;year(fecha_publicacion_llamado) =&gt; 2015&#39; # only goods condition_4: &#39;service == FALSE&#39; # no open contracts condition_5: &#39;contrato_abierto_llamado_grupo == FALSE&#39; 2.2.2.4 Adjusting for Currency and Inflation To account for inflation and exchange currencies, two datasets are required. Cotizacion, which contains the exchange rate for USD to PYG over the years, and a dataset with Consumer Price Index data. The locations of these datasets must be specified in their corresponding locations in the configuration file. Under the inflation: section, the desired base year and base month for prices to be adjusted to can be specified. currency: loc: &#39;/files/data/&#39; file: &#39;cotizacion.csv&#39; inflation: loc: &#39;/files/data/&#39; file: &#39;ipc.csv&#39; base_year: 2021 base_month: 6 2.2.2.5 Log-Transforming and One-Hot Encoding To have variables be log transformed or one-hot encoded is as simple as writing them in a list under their given categories, making sure to maintain the naming scheme of variable_dataset. 2.2.2.6 Merging Sparse Categories The configuration file contains the structure to specify which variables require condensing as well as the threshold at which condensing in done. A threshold of 0.01 indicates that any category with less than a 1% occurrence rate is reduced into an Other category. 2.2.2.7 Removing Outliers To remove outliers from the training dataset, simply set outliers: to true. Then the code to perform the isolation forest described in the Feature Engineering Remove Outliers section. "],["buyer.html", "3 Buyer Groupings 3.1 Buyer Information Fields 3.2 Adding Buyer Information to Tenders 3.3 Buyer Levels 3.4 Buyer Names and Descriptions 3.5 Most Frequent Words 3.6 Final Buyer Groupings 3.7 Variable Importance Exploration 3.8 Implementation Conclusions", " 3 Buyer Groupings 3.1 Buyer Information Fields Buyers will be considered at the tender level (i.e., one buyer for each row in the llamado table). The tables containing buyer/entity information are: unidad_contratacion left join onto pac by pac.unidad_contratacion_id = unidad_contratacion.id variable of interest: descripcion (description of the buyer; probably easiest to do text mining on, since it includes exact institution names like “hospital” or “university”) additional variables: tipo (UOC, SUOC, or UEP) and institucion (whether the buyer is an institution or not) entidad left join onto unidad_contratacion by unidad_contratacion.entidad_codigo_sicp = entidad.codigo_sicp NOTE: entidad has multiple rows for each value of entidad.codigo_sicp (one per year), so the left join must be performed using a reduced version of entidad with a single row for each value (see the code snippet below for implementation) variable of interest: nombre (name of the buyer at a higher level; does not include specific institution names, only broad government and municipality information) nivel_entidad left join onto entidad by (entidad.anio, entidad.nivel_entidad_codigo) = (nivel_entidad.anio, nivel_entidad.nivel_entidad_codigo) variable of interest: nombre (very broad buyer levels within the public sector) CONCLUSIONS: Combine unidad_contratacion.nombre and entidad.nombre into a single string to perform text mining on. Since nivel_entidad.nombre has relatively few categories with little text, it does not lend itself well to text mining. Instead, experiment with it as a categorical variable in its own right. 3.2 Adding Buyer Information to Tenders ISSUE: The buyer joining process must somehow be incorporated into the feature engineering script, but relational column inconsistencies (in terms of naming and number) and the bidirectional joining order would significantly increase the complexity of the config file. IMPLEMENTED SOLUTION: Perform the buyer joining process in a separate script, which then gets sourced within the feature engineering script if buyer-related variables are listed as predictors in the config file. 3.3 Buyer Levels We fit an OLS regression model for log_precio_unitario (our target) against nivel_entidad to see how much variability this predictor accounts for by itself. F(14,3282352) 3566.7951 R² 0.0150 Adj. R² 0.0150 Est. S.E. t val. p (Intercept) 12.4913 0.0184 678.0445 0.0000 nivel_entidadcapacitacion dncp -4.4322 1.9485 -2.2747 0.0229 nivel_entidadcontraloria general de la republica -1.0160 0.0419 -24.2320 0.0000 nivel_entidaddefensoria del pueblo -1.5444 0.0648 -23.8431 0.0000 nivel_entidadempresas mixtas 0.3968 0.0224 17.6902 0.0000 nivel_entidadempresas publicas -0.3827 0.0193 -19.7782 0.0000 nivel_entidadentes autonomos y autarquicos -0.3336 0.0195 -17.0953 0.0000 nivel_entidadentidades financieras oficiales -0.3138 0.0212 -14.8353 0.0000 nivel_entidadentidades publicas de seguridad social -0.2579 0.0202 -12.7640 0.0000 nivel_entidadgobiernos departamentales -0.2731 0.0193 -14.1613 0.0000 nivel_entidadmunicipalidades -0.5206 0.0188 -27.6727 0.0000 nivel_entidadpoder ejecutivo -0.9751 0.0186 -52.4557 0.0000 nivel_entidadpoder judicial -0.4177 0.0192 -21.7252 0.0000 nivel_entidadpoder legislativo -0.3389 0.0218 -15.5240 0.0000 nivel_entidaduniversidades nacionales -1.1089 0.0190 -58.2084 0.0000 Standard errors: OLS By itself, nivel_entidad accounts for a statistically significant 1.5% of the variability in log_precio_unitario, so we might consider including it in our model. But what about in conjunction with other predictors? ISSUE: The nivel_entidad variable has 15 categories; we must find the best way to merge them. 3.4 Buyer Names and Descriptions We join the name and description of a buyer into a single string for each tender and perform text mining. 3.5 Most Frequent Words Below are the 30 most frequent words in the buyer descriptions, along with the proportion of items for which that buyer keyword appears: 3.6 Final Buyer Groupings Since there may be overlap between the keywords present in each buyer name and description, we will be treating the buyer groupings as indicator variables (to which a buyer either belongs or not) – mutually exclusive categories would not make sense here. Some potential indicator variable groupings are: Police: \"policia\" Hospital: \"hospital\" or \"cancer\" Science: \"ciencia\" Health: \"salud\" Law: \"justicia\" or \"judicial\" Ministry: \"ministerio\" Education: \"universidad\", \"facultad\", or \"educacion\" Army: \"defensa\", \"comando\", \"armada\", or \"ejercito\" Bank: \"banco\" Tech: \"tecnologia\" or \"aeronautica\" Electricity: \"ande\" (administracion nacional de electricidad) or \"electricidad\" Grouping String Pattern Proportion police policia 3.15% hospital hospital|cancer 1.60% science ciencia 5.82% health salud 8.95% law justicia|judicial 7.11% ministry ministerio 34.52% education universidad|facultad|educacion 10.95% army defensa|comando|armada|ejercito 10.01% bank banco 1.94% tech tecnologia|aeronautica 3.39% electricity ande|electricidad 2.49% 3.7 Variable Importance Exploration Finally, we explore the importance of the above groupings when it comes to explaining the variability in log_precio_unitario. To find out which indicators might be worth keeping in the baseline regression model, we perform variable selection using the best subsets method. The importance of the different indicators might change once we include other variables, but this is a good first look at what might be most important. 10 Vars 9 Vars 8 Vars 7 Vars 6 Vars 5 Vars 4 Vars 3 Vars 2 Vars 1 Vars Adjr2 0.0246 0.0246 0.0244 0.0242 0.0236 0.0229 0.0220 0.0199 0.0157 0.0112 Cp 183.53 366.21 828.40 1574.61 3689.67 5891.46 8936.16 16108.72 30183.28 45445.77 Bic -81.63k -81.46k -81.01k -80.28k -78.18k -75.99k -72.97k -65.84k -51.87k -36.8k Police Hospital Science Health Law Ministry Education Army Bank Tech Electricity 3.8 Implementation Conclusions A total of 11 buyer indicator variables (listed above) were created based on the cleaned-up and merged buyer descriptions. Each indicator variable corresponds to certain specific string patterns, and the variable will be TRUE for a particular observation if that observation’s clean buyer description matches those patterns. Otherwise, the indicator variable will be FALSE. "],["context.html", "4 Context Groupings 4.1 Context Information Fields 4.2 Most Frequent Words 4.3 Most Frequent Word Associations 4.4 Most Influential Words 4.5 Final Context Groupings 4.6 Implementation Conclusions", " 4 Context Groupings 4.1 Context Information Fields QUESTION: What description granularity is best, keeping in mind that we want to extract the purpose/context of an item within a tender, and not descriptions that are too item-specific? OPTIONS: detalle (from llamado): highest level tender description descripcion (from llamado_grupo): middle level batch description It seems that most batch descriptions within a tender are identical, and very few tenders have batches with multiple different descriptions. Below is a summary of the number of unique batch descriptions per tender, which shows that the vast majority of tenders have around 1 or 2 different batch descriptions: Min. 1st Qu. Median Mean 3rd Qu. Max. 1 1 1 4.589865 2 1692 Let’s explore the tenders with the highest number of different batch descriptions: Tender Description Adquisicion De Textos Eductativos Adquisicion De Reactivos, Gases Especiales, Vidrios Y Elementos De Laboratorio Adquisición De Reactivos E Insumos De Laboratorio Para Programas De Salud Y Laboratorio Central Adquisicion De Productos Quimicos Y Medicinales Para La Facultad De Ciencias Medicas, Hospital De Clinicas Y El Centro Materno Infantil Adquisicion De Libros Para La Facultad De Derecho Adquisición De Libros Para La Biblioteca Adquisicion De Medicamentos E Insumos Medicos Y Odontologicos Para Adquisicion De Repuestos, Cubiertas, Baterias Y Otros Para Vehiculos De La Dinac Adquisicion De Productos Quimicos Y Medicinales Para La Facultad De Ciencias Medicas, El Hospital De Clinicas/Sajonia - San Lorenzo Adquisicion De Productos E Instrumentales Quimicos Y Medicinales Adquisicion De Medicamentos, Insumos, Reactivos Y Productos Odontologicos Varios Adquisicion De Libros Para La Biblioteca De La Facultad Lpn N° 01/12 Adquisicion De Reactivos E Insumos Para Laboratorio Central De Salud Publica Para La Adquisición De Articulos De Ferreteria Adquisicion De Libros Para La Biblioteca Del Congreso De La Nación Adquisicion De Reactivos Quimicos E Insumos De Laboratorio, Con Equipos En Comodato. Adquisicion De Medicamentos, Insumos, Reactivos Y Productos Odontologicos Varios Adquisicion De Reactivos Quimicos E Insumos De Laboratorio, Con Equipos En Comodato Adquisicion De Productos E Instrumentales Quimicos Adquisicion De Repuestos Y Accesorios Mayores Para Aeronaves Adquisición De Libros Para La Facultad De Derecho Y Ciencias Sociales Una Adquisicion De Insumos Varios Para La Municipalidad De Asuncion Adquisicion De Reactivos E Insumos Para Hospitales Especializados Y Laboratorio Central De Salud Publica Adquisicion De Repuestos Mayores Para Aeronaves (Ad Referendum) (Plurianual) Lpn N° 51/2017 Adquisicion De Insumos Y Reactivos Para Laboratorio Central De Salud Publica - Cobertura 24 Meses Del Msp Y Bs Adquisición De Libros Para La Biblioteca Y Archivo Central Del Congreso Nacional Adquisición De Libros Para La Dirección General De Cultura Y Turismo Adquisición De Materiales Bibliográficos Para El Instituto De Trabajo Social Dependiente Del Rectorado Una Adquisición De Libros Para La Biblioteca Y Archivo Central Adquisición De Libros Para La Biblioteca Y Archivo Central Del Congreso Nacional Tenders that have batches with many different descriptions tend to consist of: books / educational materials (case in which the description of each batch might include the book title) laboratory substances and/or chemical supplies medicine and hospital products batteries and spare parts for cars CONCLUSION: It seems best to focus on detalle from llamado (the highest level tender description). 4.2 Most Frequent Words Below are the 30 most frequent words in the tender descriptions, along with the proportion of items for which that tender keyword appears: The top 100 most frequent words in tender descriptions are listed below: vehiculo, construccion, oficina, plurianual, referendum, util, insumo, material, menor, repuesto, articulo, electrico, aula, edificio, ferreteria, institucion, nacional, vario, provision, limpieza, llamado, laboratorio, hospital, central, abierto, accesorio, reactivo, papel, varia, tinta, educativa, maquinaria, departamento, aire, herramienta, preventivo, obra, justicia, elemento, escuela, medicamento, correctivo, toner, fonacide, marca, electoral, informatico, distrito, muebl, centro, segundo, alimenticio, municipal, acondicionador, comedor, libro, quimico, ciudad, medico, ceremonial, alimento, ampliacion, seguro, sanitario, facultad, fotocopiadora, asuncion, gastronomico, pintura, salud, cocina, carton, impresion, local, bano, instalacion, parque, automotor, publica, ministerio, empedrado, dependencia, infraestructura, impresora, general, cordillera, modalidad, persona, regional, sistema, ciencia, impreso, camara, escritorio, refaccion, evento, basica, cubierta, licitacion, mejoramiento 4.3 Most Frequent Word Associations It is important to see how associated these words are, in order to help us identify words that commonly occur together in tender descriptions. The table below shows the top 20 most associated word pairs (i.e., the word pairs that most commonly appear together, as measured using the Pearson correlation of the indicator variables): First Word Second Word Correlation preventivo correctivo 0.93 justicia electoral 0.91 parque automotor 0.87 facultad ciencia 0.82 aire acondicionador 0.82 oficina util 0.78 llamado segundo 0.75 impresora impreso 0.72 limpieza elemento 0.70 articulo ferreteria 0.69 tinta toner 0.68 institucion educativa 0.67 comedor cocina 0.66 infraestructura mejoramiento 0.62 papel carton 0.60 alimento persona 0.58 abierto modalidad 0.57 camara cubierta 0.55 escuela basica 0.53 material electrico 0.51 4.4 Most Influential Words Further, we fit a linear regression model based on an indicator associated with each of the top 100 words, to see which ones are most highly associated with our respose (the unitary price). The table below shows the top 20 words with the highest absolute coefficient in the simple linear regression: Word Absolute Regression Coefficient alimenticio 3.22 impresion 3.11 carton 3.05 alimento 2.93 papel 2.88 util 2.61 elemento 2.60 persona 2.55 escritorio 2.45 seguro 2.31 limpieza 2.30 medicamento 2.29 sistema 2.23 correctivo 2.21 marca 2.19 preventivo 2.19 articulo 2.17 ferreteria 2.06 material 1.81 muebl 1.77 4.5 Final Context Groupings Based on these tables, we have manually compiled a list of context groupings with their corresponding string patterns: Food: \"alimento\" or \"alimenticio\" Vehicle: \"vehiculo\" Construction: \"construccion\", \"edificio\", or \"obra \" Hardware: \"ferreteria\" or \"herramienta\" Preventive Corrective: \"preventivo\" or \"correctivo\" Real Estate: \"inmuebl\" Office: \"oficina\", \"tinta\", \"toner\", \"papel\", \"fotocopiadora\", \"impreso\", or \"impresion\" Specialized Supplies: \"insumo\" Cleaning: \"limpieza\" Politics: \"electoral\" or \"justicia\" Medical: \"hospital\", \"medicamento\", \"medico\", \"hemato\", or \"onco\" Chemical: \"reactivo\", \"laboratorio\", \"quimico\", or \"quimica\" Insurance: \"seguro\" Specific Brand: \"marca \" Electricity: \"electric\" Kitchen: \"cocina\", \"comedor\", or \"gastronomic\" Computer: \"informatico\" or \"computadora\" Air Conditioning: \"aire\" or \"acondicionado\" Spare Part: \"respuesto\" Machine: \"maquinaria\" Fuel: \"combustible\" or \"diesel\" Around 70% of items fall under at least one of the above groupings. Fitting a linear regression model using only the indicator variables based on these groupings, we manage to account for almost 19% of the variability in unitary prices, which is extremely promising: F(21,3282345) 36084.1745 R² 0.1876 Adj. R² 0.1876 Est. S.E. t val. p (Intercept) 12.1423 0.0023 5361.9510 0.0000 foodTRUE -3.2897 0.0086 -380.9883 0.0000 vehicleTRUE 0.7931 0.0045 175.6510 0.0000 constructionTRUE 0.4307 0.0039 109.1456 0.0000 hardwareTRUE -1.6044 0.0068 -236.2270 0.0000 preventive_correctiveTRUE 1.5202 0.0106 143.9135 0.0000 real_estateTRUE 2.3152 0.0266 87.1959 0.0000 officeTRUE -1.6542 0.0043 -380.6688 0.0000 specialized_suppliesTRUE -1.0580 0.0065 -163.7480 0.0000 cleaningTRUE -2.3169 0.0088 -263.0913 0.0000 politicsTRUE 0.1428 0.0102 13.9352 0.0000 medicalTRUE -0.5435 0.0065 -83.1100 0.0000 chemicalTRUE -0.2402 0.0075 -32.2029 0.0000 insuranceTRUE 1.2738 0.0128 99.7132 0.0000 specific_brandTRUE 1.2005 0.0111 108.0571 0.0000 electricityTRUE -1.3175 0.0069 -190.8420 0.0000 kitchenTRUE -0.9701 0.0085 -113.7696 0.0000 computerTRUE 1.4072 0.0108 130.8460 0.0000 air_conditioningTRUE 0.5920 0.0097 60.9804 0.0000 spare_partTRUE -0.9954 0.0413 -24.1000 0.0000 machineTRUE 0.8762 0.0102 85.9189 0.0000 fuelTRUE -1.9991 0.0418 -47.8257 0.0000 Standard errors: OLS 4.6 Implementation Conclusions A total of 21 context indicator variables (listed above) were created based on the cleaned-up tender descriptions. Each indicator variable corresponds to certain specific string patterns, and the variable will be TRUE for a particular observation if that observation’s clean tender description matches those patterns. Otherwise, the indicator variable will be FALSE. "],["outlier.html", "5 Outlier Removal 5.1 Anomaly Scores 5.2 Outlier Statistics 5.3 Outlier Descriptions 5.4 Implementation Conclusions", " 5 Outlier Removal 5.1 Anomaly Scores As mentioned in the automated EDA documentation, outlier detection is performed using an isolation forest, which assigns to each observation an anomaly score (from 0 to 1). The plots below display histograms of the anomaly scores, with the left-hand side plot being the origial anomaly scores, while the right-hand side plot shows the log-transformed scores. Based on the significant skew of the anomaly score distribution (with most observations having a score around 0.58), the cutoff point for outliers was chosen to be 0.6. All observations with anomaly scores greater than 0.6 are considered outliers. 5.2 Outlier Statistics This cutoff point results in 8672 outliers overall, a mere 0.26% of the total items. 4647 tenders (or 3.14% of all tenders) contain at least one item that is a price outlier. These percentages are very low, which is great since we are removing a very small amount of data in exchange for a huge increase in model focus and accuracy. The minimum price of the outliers (or the price cutoff per se) is 185,525,450 Paraguayan guarani (May 2021) or $27,829. The plot below displays a log-transformed density plot of the unitary prices, with a red dotted line drawn at the aforementioned cutoff of 185 million guarani. All prices within the red shaded area are considered outliers and removed before training the model. 5.3 Outlier Descriptions Finally, it is important to actually take a look at the outliers and see what exactly they entailed. Below are the tender and item descriptions of the top 20 most extreme outliers in terms of price. They include things like fuels (diesel, crude oil), road paving services, hydroelectric power plant construction, and cable-stayed bridge construction. Tender Description Item Description Aquisición De Combustible De Petropar Petroleo Crudo Adquisicion De Combustible Diesel Llamado Mopc Nº 156/2019 Licitación Publica Nacional Para La Contratación De Empresas Constructoras Para La Construcción De Un Puente Sobre El Rio Paraguay Entre Asunción(Capital) Y Chaco I (Departamento De Presidente Hayes) Ad Referéndum A La Ampliación Presupuestaria Construccion De Un Puente Sobre El Rio Paraguay Entre Asuncion (Capital) Y Chaco’i (Departamento De Presidente Hayes) Lp01007-14. Obras Civiles E Hidromecánicas, Lote 2 Del Proyecto De Construcción De La Central Hidroeléctrica Yguazú, A Travéz Del Convenio De Préstamo Pg-P15. Asentamiento / Cimiento De Hormigon Obras Para Presas Hidroeléctricas Para Empresas Precalificadas, Obras Civiles Y Obras Hidromecánicas, Contempladas En El Lote 2, En El Marco Del Proyecto De Construcción De La Central Hidroeléctrica Yguazú, A Través Del Contrato De Préstamo Pg-P15. Preparacion De Obra Lpi 1561-20.Proyecto De Construcción E Interconexión De La Subestación Valenzuela 500 Kv Construcción De La Se Valenzuela 500 Kv Y De Las Lineas De Seccionamientoen 500 Y 220 Kv Llamado Mopc Nº 52/2015 Licitacion Publica Internacional De Empresas Constructoras Especializadas En Obras Viales Para La Construccion De La Avenida Costanera Norte De Asuncion - Segunda Etapa Y Conexion De La Avenida Primer Presidente Con La Ruta Nacional N° 9 Servicio De Construccion De Asfaltado O Pavimentacion Lpi De Empresas Constructoras Para Obras De Rehabilitación Y Mantenimiento De La Ruta Nº 9 Y Accesos, Tramo 3 Lote 5 Y 6 - Ad Referendum A La Reprogramacion Presupuestaria Servicio De Construccion De Asfaltado O Pavimentacion Lp1542-19 Proyecto De Construcción E Interconexión De La Subestación Yguazú 500 Kv - Ad Referéndum Construcción De La Subestación En 500/220/23 Kv Yguazú Lpi De Empresas Constructoras Para Obras De Rehabilitación Y Mantenimiento De La Ruta Nº 9 Y Accesos, Tramo 3 Lote 5 Y 6 - Ad Referendum A La Reprogramacion Presupuestaria Servicio De Construccion De Asfaltado O Pavimentacion Llamado Mopc 118/16. Diseño Y Construccion De Las Oficinas De Gobierno Diseño Y Construccion De Las Oficinas De Gobierno Licitación Publica Internacional De Empresas Constructoras Para Obras De Habilitación Y Mantenimiento De La Ruta N°9 Y Accesos, Tramo 4: Lote 7. Ad Referéndum Al Pgn 2020 Mantenimiento / Reparacion De Asfaltado Lp1044-2014 Construcción De La Línea De Transmisión 500 Kv Yacyreta - Ayolas - Villa Hayes Construcción De La Línea De Transmisión 500 Kv Yacyretá - Ayolas - Vértice N° 20 - (Tramo 1) Lp1044-2014 Construcción De La Línea De Transmisión 500 Kv Yacyreta - Ayolas - Villa Hayes Construcción De La Línea De Transmisión 500 Kv - Vértice N° 20 - Villa Hayes - (Tramo 2) Llamado Mopc Nº 86/2014 - Licitación Pública Internacional De Empresas Constructoras Especializadas En Obras Viales Para La Habilitación De La Ruta Nacional Nº 9. Tramo Mcal. Estigarribia - La Patria (58 Km) Y Mantenimiento Del Tramo La Patria - Tte Infante Rivarola (115 Km) Fase 2. Ad Referendum A La Aprobacion Del Prestamo Con La Caf Servicio De Construccion De Asfaltado O Pavimentacion Mopc Nº 52-13 Lpi Emp. Constructoras Especializadas En Obras Viales Precal. P/ La Ejecucion De Las Obras De Rehabilitacion Y Pavimentacion De La Ruta Nº 8 Dr. Blas G. Tramo Caazapa - Yuty Y Accesos Servicio De Construccion De Asfaltado O Pavimentación Ejecución De Las De Las Obras De Mejoramiento De La Ruta Nº 3 - Gral. Elizardo Aquino, Tramo Bella Vista Norte ? Empalme Ruta N°5. Dpto. Departamento De Amambay Y Concepcion Mejoramiento De La Ruta Nº 3- Y Ruta Nº 5. Dpto. De Amambay Llamado Mopc Lpi Nº 04/2020. Empresas Constructoras Para La Pavimentacion Del Tramo Desvio Alberdi -Pilar Tramo/ Obra 1 - Alberdi - Rio Tebicuary (51,56 Km) Y Travesia Urbana Villa Franca (2,05 Km) Construcción Para La Pavimentación Del Tramo Desvio Alberdi-Pilar Llamado Mopc N° 89/2020 Solicitud De Ofertas Mediante Licitación Pública Internacional Para La Ejecución De Obras Viales De Habilitación Y Mantenimiento De Corredores Agroindustriales Ruta De La Leche (Región Occidental) Con Id N° 386.505. Ad Referendum De La Aprobacion Del Contrato De Prestamo. Cruce Pioneros Paratodo Desde Progresiva 48+400 Incluido El Tramo Paratodo - Cruce Douglas Desde Progresiva 0+000 Hasta Progresiva 5 +100, El Acceso A Campo Aceval Y El Tramo Campo Aceval Progresiva 29 +500 (71,47 Km) Llamado Mopc Nº 40/2018 - Lpi De Empresas Constructoras Para La Rehabilitación Y Pavimentación Del Tramo 1: Desvio Alberdi - Rio Tebicuary (51,56 Km) Y Travesia Urbana Villa Franca (2,297 Km) Rehabilitacion Y Pavimentacion Del Tramo Desvio Alberdi - Pilar Tramo/Obra 1. Desvio Alberdi-Rio Tebicuary (51,56 Km) Y Travesia Urbana Villa Franca (2,297 Km) 5.4 Implementation Conclusions With the current state of the data, a cutoff value of 0.6 was chosen for the anomaly scores (though this can be changed manually in the feature engineering configuration file). All observations that have anomaly scores of at least 0.6 assigned by the random forest algorithm are considered to be outliers and removed from the training dataset before fitting the model. "],["eda.html", "6 Exploratory Data Analysis 6.1 The PDF File 6.2 The Data Dictionary", " 6 Exploratory Data Analysis 6.1 The PDF File The automated exploratory data analysis file, reports/training_set_eda.Rmd, is written in R Markdown and is re-knit automatically every time the user runs the feature engineering script fe.R. The result is reports/training_set_eda_DATE.pdf, which includes a number of summary statistics as well as uni- and multivariate visualizations of the variables in the training set. 6.1.1 Types of EDA Performed 6.1.1.1 Summary Statistics Summary statistics are generated for all numerical variables. They include the minimum, first quartile, mean, median, third quartile, maximum, and percentage of missing values. This can help when assessing skew and choosing proper measures of center (e.g., if the mean and median differ significantly), and the percentage of missing values can help when deciding whether to impute missing values or to simply discard them. 6.1.1.2 Distribution Plots Distribution plots (namely histograms and density plots) are created for all numerical variables. These plots help detect things like skew (which suggests the need for a logarithmic transformation) or whether parmetric assumptions (e.g., normality) are satisfied. The R Markdown script automatically detects whether a variable is highly skewed (based on the third sample moment), and in such a case it will log-transform the variable before plotting it. This eases visualization, and it is easy to notice thanks to the \\(x\\)-axis label, which will include the text “(log)” after the variable name. 6.1.1.3 Boxplots Boxplots are created for all numerical variables, and they once again help detect skew. Further, boxplots are useful in that they can highlight the number and of outliers (i.e., observations more than 1.5 IQRs away from either quartile), which is something that might not be immediately visible in histograms or density plots. 6.1.1.4 Correlation Plots Correlation plots are generated for all numerical variables, and their purpose is two-fold. First, they can help detect non-linear relationships between predictors and the response, which might cause us to rethink using a linear model. Further, they help detect predictors that are highly correlated with each other, which can lead to multicollinearity in some models (i.e., a high variance inflation factor). This is a sign that one of the predictors should be excluded from the model. 6.1.1.5 Barplots Barplots are created for all categorical variables. For each categorical variable, they display the number of observations in each category, ordered from highest to lowest count (with an exact label on top of each bar). The very last bin always displays the count of missing values, which can suggest the need for imputation or other handling methods if the missingness count is too high relative to other categories. The barplots can also help with detecting the sparse categories that are being merged within the feature engineering script, so that one can assess the soundness of this merging step and take action accordingly. 6.2 The Data Dictionary The data dictionary is required for the automated EDA to run properly, and it needs to list every single variable of interest. It can be found in conf/meta/training_set_data_dict_VERSION.xlsx: number name description type binary role use comment 1 precio_unitario_item_solicitado NA num N target Y NA 2 presentacion_item_solicitado NA cat N predictor N NA 3 agricultura_familiar_item_solicitado NA cat Y predictor Y NA 4 produccion_nacional_item_solicitado NA cat Y predictor Y NA 5 contrato_abierto_llamado_grupo NA cat Y predictor Y NA 6 forma_adjudicacion_llamado NA cat N predictor Y NA 7 forma_pago_llamado NA cat N predictor Y NA 8 tipo_unidad_contratacion NA cat N predictor Y NA 9 institucion_unidad_contratacion NA cat Y predictor Y NA 10 nombre_nivel_entidad NA cat N predictor Y NA 11 service NA cat Y predictor Y NA 12 police_buyer NA cat Y predictor Y NA 13 hospital_buyer NA cat Y predictor Y NA 14 health_buyer NA cat Y predictor Y NA 15 law_buyer NA cat Y predictor Y NA 16 ministry_buyer NA cat Y predictor Y NA 17 education_buyer NA cat Y predictor Y NA 18 army_buyer NA cat Y predictor Y NA 19 tech_buyer NA cat Y predictor Y NA 20 electricity_buyer NA cat Y predictor Y NA 21 descripcion_ingles_producto_n1 NA char N predictor Y NA 22 cantidad_item_solicitado NA num Y predictor Y NA 23 food_context NA cat Y predictor Y NA 24 vehicle_context NA cat Y predictor Y NA 25 construction_context NA cat Y predictor Y NA 26 hardware_context NA cat Y predictor Y NA 27 preventive_corrective_context NA cat Y predictor Y NA 28 real_estate_context NA cat Y predictor Y NA 29 office_context NA cat Y predictor Y NA 30 specialized_supplies_context NA cat Y predictor Y NA 31 cleaning_context NA cat Y predictor Y NA 32 politics_context NA cat Y predictor Y NA 33 medical_context NA cat Y predictor Y NA 34 chemical_context NA cat Y predictor Y NA 35 insurance_context NA cat Y predictor Y NA 36 specific_brand_context NA cat Y predictor Y NA 37 electricity_context NA cat Y predictor Y NA 38 kitchen_context NA cat Y predictor Y NA 39 computer_context NA cat Y predictor Y NA 40 air_conditioning_context NA cat Y predictor Y NA 41 spare_part_context NA cat Y predictor Y NA 42 machine_context NA cat Y predictor Y NA 43 fuel_context NA cat Y predictor Y NA The key fields in the data dictionary are: name (the variable name, as generated by the feature engineering script) type (num for numerical, cat for categorical or logical, and char for string) role (predictor or target) use (Y if to include the variable in the automated EDA, N otherwise) "],["train.html", "7 Training 7.1 The Script 7.2 The Configuration File", " 7 Training 7.1 The Script The training script, training.R, creates a stratified train/test split, performs hyperparameter tuning, trains a model, and outputs key performance indicators (KPIs). 7.1.1 Required Files The training.R script is not a self contained script and requires the input of a training dataset and other scripts containing helper functions. The following is a list of necessary files and the structure they should follow: src/ scripts/ training.R (encompassing script to run) functions/ training_helpers.R (set of helper functions to perform tasks in training.R) data/ output/ training_set_DATE.rds (most recent training dataset created by fe.R) conf/ training_conf.yaml (configuration file for training.R) 7.1.2 Required R Packages The following is a list of R VERSION 4.1.0 packages necessary for running training.R and its associated scripts and reports yaml 2.2.1 tidyverse 1.3.1 mlr3verse 0.2.1 7.1.3 Tasks Performed by the Script The training.R script takes in a cleaned and feature engineered dataset outputted by fe.R. To understand how to accomplish this output, please look at the Feature Engineering Documentation. 7.1.3.1 Creating the Train/Test Split For model creation, the dataset is split into two subsets: a training set and test/holdout set. The training set is used to train a model, while the testing set is withheld from the training to try to simulate unseen data. Once a model is created using the training set, it is used to predict the prices in the test/holdout set Since, we have the observed prices for the contracts in the test/holdout set, we can evaluate the predictions. It is ideal for the training set and test/holdout set to have similar distributions of the target variable. Thus, to create the train and test sets, a stratified sampling technique was used to split the dataset. To do this, Sturges’ Rule was used – a principle providing guidelines on how many bins a dataset should be split up into. Using the formula for Sturges’ Rule and the number of rows in the dataset, the stratified sampling technique was used such that first, the data was sorted by the target variable. Next, \\(\\big\\lceil \\log_2 n\\big\\rceil + 1\\) strata were created from the sorted data with \\(n\\) rows. Lastly, a random proportion of each strata was selected to be part of the training set. This allows for the training set to have a target variable distribution similar to the original full dataset. It is also important to note that all observations where the target value is missing are removed. We do not want to risk imputing the value of the target variable, so we drop missing values. To see how missing values are handled for predictor variables see the Feature Engineering Documentation. 7.1.3.2 Setting Up the Model The modeling for this project was all conducted using the mlr3 ecosystem. The ecosystem provides a universal framework for different models and enabled us to create a dynamic training script which can develop any type of model. The set up simply involves designating which variable is the target and which are predictors. Then choosing which type of model is going to be developed, and assigning values to desired parameters for the given model choice. A random forest and a neural network have vastly different parameter inputs such as number of trees vs learning rate, but we have implemented a system that enables for easy input of these values. Once the inputs of the model are established, the desired algorithm is ran. Depending on the algorithm, this can take seconds to hours. 7.1.3.3 Hyperparameter Tuning Due to this high degree of choice in parametric values, it is common to choose values based on reputation, intuition, or just adhere to the defaults. But, there is an algorithmic approach to use hyperparameter tuning to identify the ideal values for the given hyperparameters instead of manually inputting and guessing. Note that hyperparameter can be used interchangable with parameter in this context as a hyperparameter is just a parameter for a machine learning model. Through a structured hyperparameter-tuning process, various parametric configurations are evaluated on the same data splits using a resampling holdout set. Eventually, the configuration with the best performance is outputted, which can then be used to train a model. 7.1.3.4 Storing Model and KPIs Once the model is developed, the key performance indicators (KPIs) that are specified in training_conf.yaml are calculated and outputted to the console. The model is then stored to the output destination. 7.1.4 Outputs The following are the outputs produced by running training.R: output/MODELNAME_DATE.rds (trained model where MODELNAME is the name section in the config file) printed model KPIs, e.g. Non-Log RMSE: 24298515.95595 PYG (3644.77739 USD) Non-Log Median RMSE: 33708.62962 PYG (5.05629 USD) 7.2 The Configuration File The configuration file training_conf.yaml contains the inputs for the tasks outlined in the Training Documentation. This file needs to be altered for any desired change of input. The following sections describe how to make those alterations. Every value must be stored in quotation marks unless it is a number or boolean (TRUE/FALSE). The training configuration file is broken down into three stages: the Data, the Features, and the Model. 7.2.1 Data To load in the correct training dataset, the file location is sepcified under loc:, and the most recent run date of fe.R is entered in the last_run_date section. The input location in this configuration file should be the same as the output location in fe_conf.yaml. data: loc: &#39;~/dncp/data/output&#39; last_run_date: &#39;2021-07-29&#39; 7.2.1.1 Features Under the features section, the desired target, id, and predictor variables are specified explicitly using the naming convention variable_dataset. For one-hot encoded variables, it is not necessary to state each column created for each category, solely add the overall column name. However, it is important each variable is contained within quotation marks. Below is an example. features: id: &#39;item_solicitado_id&#39; # unique id target: &#39;precio_unitario_item_solicitado_log&#39; # all predictors to be used, including groups and one-hot encoded variables predictors: [&#39;contrato_abierto_llamado_grupo&#39;, &#39;agricultura_familiar_item_solicitado&#39;, &#39;produccion_nacional_item_solicitado&#39;, &#39;service&#39;, &#39;descripcion_ingles_producto_n1&#39;, &#39;police_buyer&#39;, &#39;electricity_buyer&#39;, &#39;food_context&#39;, &#39;vehicle_context&#39;] For variables that were one-hot encoded, explicitly specify their original name under the one_hot_encoded_vars section IN ADDITION to being in the predictor section. one_hot_encoded_vars: [&#39;tipo_unidad_contratacion&#39;, &#39;nombre_nivel_entidad&#39;, &#39;forma_adjudicacion_llamado&#39;, &#39;forma_pago_llamado&#39;, &#39;descripcion_ingles_producto_n1&#39;] 7.2.2 Model The model building section of training_conf.yaml has the most variation in terms of inputs. The name key is to uniquely identify the training run, and will be included in the filename of the stored model. It is recommended to include the model type in the name. Additionally, the model section is where the train/test split proportions are specified. Typical splits are 70% (or 80%) of the data used for training and the remaining 30% (or 20%) used for testing. Input the proportion for the training set under train_prop as a decimal value. model: name: &#39;ranger-no-outliers&#39; train_prop: 0.8 In this model section, the desired algorithm can be specified under the type section. The selection must be an acceptable mlr3 algorithm, where the list of possibilities can be found entering mlr3verse::mlr_learners into the R console or looking below: classif.cv_glmnet, classif.debug, classif.featureless, classif.glmnet, classif.kknn, classif.lda, classif.log_reg, classif.multinom, classif.naive_bayes, classif.nnet,classif.qda, classif.ranger, classif.rpart, classif.svm, classif.xgboost, clust.agnes, clust.ap, clust.cmeans, clust.cobweb, clust.dbscan, clust.diana, clust.em, clust.fanny, clust.featureless, clust.ff, clust.kkmeans, clust.kmeans, clust.MBatchKMeans, clust.meanshift, clust.pam, clust.SimpleKMeans, clust.xmeans, dens.hist, dens.kde, regr.cv_glmnet, regr.featureless, regr.glmnet, regr.kknn, regr.km, regr.lm, regr.ranger, regr.rpart, regr.svm, regr.xgboost, surv.coxph, surv.cv_glmnet, surv.glmnet, surv.kaplan, surv.ranger, surv.rpart, surv.xgboost 7.2.2.1 Parameter Choices The next and most important aspect of the model development is the parameters. Each algorithm has various different parameters that can be adjusted, so it was important to enable access to those options regardless of the algorithm. Say the desired model type is a random forest. In the mlr3 ecosystem, a random forest regression is the model ‘regr.ranger’. To find the options for the parameters, enter mlr3verse::lrn(\"regr.ranger\")$param_set into the R console. The important information is the output are the id, lower, upper, and default columns. The id is the name of the parameter, the lower and upper values are the bounds for the parameter. When the bounds are -Inf to Inf, this means it can be any numeric value. When the bounds are NA and the nlevels is 2, then this is a TRUE/FALSE parameter. The default is what the parameter is automatically set to when running the algorithm. Parameters should only be customized if the default value is not desired. The example output for regr.ranger is below: id class lower upper nlevels default 1: alpha ParamDbl -Inf Inf Inf 0.5 2: always.split.variables ParamUty NA NA Inf &lt;NoDefault[3]&gt; 3: holdout ParamLgl NA NA 2 FALSE 4: importance ParamFct NA NA 4 &lt;NoDefault[3]&gt; 5: keep.inbag ParamLgl NA NA 2 FALSE 6: max.depth ParamInt -Inf Inf Inf 7: min.node.size ParamInt 1 Inf Inf 5 8: min.prop ParamDbl -Inf Inf Inf 0.1 9: minprop ParamDbl -Inf Inf Inf 0.1 10: mtry ParamInt 1 Inf Inf &lt;NoDefault[3]&gt; 11: num.random.splits ParamInt 1 Inf Inf 1 12: num.threads ParamInt 1 Inf Inf 1 13: num.trees ParamInt 1 Inf Inf 500 14: oob.error ParamLgl NA NA 2 TRUE 15: quantreg ParamLgl NA NA 2 FALSE 16: regularization.factor ParamUty NA NA Inf 1 17: regularization.usedepth ParamLgl NA NA 2 FALSE 18: replace ParamLgl NA NA 2 TRUE 19: respect.unordered.factors ParamFct NA NA 3 ignore 20: sample.fraction ParamDbl 0 1 Inf &lt;NoDefault[3]&gt; 21: save.memory ParamLgl NA NA 2 FALSE 22: scale.permutation.importance ParamLgl NA NA 2 FALSE 23: se.method ParamFct NA NA 2 infjack 24: seed ParamInt -Inf Inf Inf 25: split.select.weights ParamDbl 0 1 Inf &lt;NoDefault[3]&gt; 26: splitrule ParamFct NA NA 3 variance 27: verbose ParamLgl NA NA 2 TRUE 28: write.forest ParamLgl NA NA 2 TRUE Say that from the output of the parameters, it is decided that the parameters to customize are the number of trees, the number of variables randomly split on for each tree, and whether or not to replace samples. Their custom values are inputted into the parameter section using key-value pairs where the key is the id and the value is within the upper and lower bounds. type: &quot;regr.ranger&quot; parameters: num.trees: 501 mtry: 10 replace: FALSE 7.2.2.2 Hyperparameter Tuning The next step is hyperparameter tuning, which, depending upon the grid size and parameter selection, might take hours to run. Thus, in the configuration file, this step can be ignored by setting run to FALSE. Using the tuner ‘grid_search’, all possible combinations of hyperparameters are tested between the specified lower, upper bounds for each parameter, and similarly, ‘random_search’ will randomly choose values. The higher the number of discrete values for hyperparameters and the more hyperparameters, the more computationally expensive. We recommend also specifying a budget of 20 evaluations using n_evals. hyperparameter_tuning: run: true tuner: &#39;random_search&#39; n_evals: 20 As seen in the Parameter Configuration section, the individual parameters are model-dependent and thus need to be adjusted for each algorithm. Refer to that section on how to identify parameters and their bounds. Once the desired parameters are identified, the configuration file should be filled out with three nested key value pairs of type, lower and upper for each parameter, where type is the data type (‘int’ is integer, ‘dbl’ is double, ‘fct’ is factor, and ‘lgl’ is logical), and the lower and upper values are the desired bounds for the parameter. These bounds must be inbetween the overall bounds for the parameter, but should only be the range that is desired for testing. For example, the variable x may be allowed to be any value btween 0 and 100, but it is only desired to test values between 30 and 40, so the bounds are set at 30 and 40. Once the ideal parameters are determined, the script will add them to the model before it is trained. Below is an example configuration for an XGBoost model: parameters: eta: type: &#39;dbl&#39; lower: 0 upper: 1 max_depth: type: &#39;int&#39; lower: 1 upper: 100 subsample: type: &#39;dbl&#39; lower: 0 upper: 1 nrounds: type: &#39;int&#39; lower: 40 upper: 400 Additionally, here is an example for a random forest algorithm: parameters: mtry: type: &#39;int&#39; lower: 1 upper: 15 ntree: type: &#39;int&#39; lower: 500 upper: 1550 7.2.2.3 Metrics The final step is to list the key performance indicators for evaluation under the metrics section. Once again, these must be written in using the naming conventions of mlr3. metrics: [&quot;regr.rmse&quot;, &quot;regr.mae&quot;, &quot;regr.rsq&quot;] "],["predict.html", "8 Application &amp; Prediction 8.1 The Script 8.2 The Configuration File", " 8 Application &amp; Prediction 8.1 The Script The prediction script takes new raw data as inputs, and performs necessary feature engineering on the data consistent with the feature engineering done before model training and then uses a previously trained model to predict the unit price of each row in the data. The output consists of an Excel file with the merged new raw data that also contains these predictions. 8.1.1 Required Files The predict.R script is not a self-contained script and requires the input of new raw data and other scripts containing helper functions. The following is a list of necessary files and the structure they should follow within the dncp folder: src/ scripts/ predict.R (encompassing script to run) functions/ predict_helpers.R (set of helper functions to perform tasks in predict.R) fe_helpers.R (set of helper functions to conduct feature engineering tasks in predict.R) conf/ predict_conf.yaml (configuration file for predict.R) merge_sparse.yaml (configuration file containing categories after merging sparse categories) valid_categories.yaml (configuration file containing values to be used to replace new categories in categorical variables) In addition to the above files, the predict.R script requires new raw data that the user wishes to generate predicted unit price values for. The required datasets are listed below, and they should all be stored in the same directory; the name of this directory should be inputted into the predict_conf.yaml file at data$loc (the default directory is data/raw/). data item_solicitado.csv llamado_grupo.csv llamado.csv pac.csv producto_n5.csv producto_n4.csv producto_n3.csv producto_n2.csv producto_n1.csv unidad_contratacion.csv entidad.csv nivel_entidad.csv 8.1.2 Required R Packages The following is a list of R packages necessary for running predict.R and its associated scripts and reports. caret lubridate solitude tidyverse yaml openxlsx glue 8.1.3 Tasks Performed in the Script The predict.R script takes in an already trained model that is used to predict unit price values for the new raw data. For more information on how such models are trained, please look at Training Documentation. 8.1.4 Feature Engineering on New Data Once the new raw datasets are loaded and merged in predict.R, they are adjusted through feature engineering tasks so that they are in the correct format to apply the model on them. The feature engineering tasks will be briefly reviewed in this section, but for more specific information on the separate tasks, please look at Feature Engineering Documentation. A new variable is first created in the dataset that indicates whether an item is a good or a service (denoted with a 1 if the item is a service and 0 otherwise). Then, any pre-set filters in the feature engineering configuration file are applied to the dataset, filtering out specific rows as desired. Next, prices in the dataset are adjusted for inflation, and new grouping variables indicating the buyer of each item and the context of each item (i.e. what they are used for) are added. Then, the predictor variables, as well as extra variables providing descriptions of each item and the date of their execution in public procurement, are selected from the overall dataset. Next, any skewed numeric variables are log-transformed as specified in the feature engineering configuration file, after which sparse categories are merged based on which categories remained after merging in the feature engineering script; these categories are saved in the merge_sparse.yaml configuration file. The sparse categories are determined by first identifying in the feature engineering script which categories in each categorical variable have the lowest frequencies; those categories are then saved, and they are merged in the predict.R script regardless of their frequencies in the new raw input data. This is required in order to stay consistent with findings from the training dataset. A one-hot encoding model previously saved from the fe.R script is then loaded and applied to the new raw data; the model can be specified in the predict_conf.yaml configuration file (see below). The one-hot encoding creates a new binary indicator variable for each category in categorical variables in the data (i.e. if one category in the categorical variable fruit is apple, then one-hot encoding would create a new binary variable apple that is equal to 1 if the item is in the apple category and 0 otherwise). New categories in categorical variables are set to the corresponding category in valid_categories.yaml, which is either the “Other” category or the most frequent category in the categorical variable. Lastly, any missing values are imputed by assigning NA or 0 to appropriate missing feature variables values. 8.1.5 Making Predictions on New Data After the feature engineering is complete, a previously saved model is loaded to make predictions on the completely adjusted new data. The saved model is loaded from an existing RDS file generated from the training.R script; the model can be specified in the predict_conf.yaml configuration file (see below). Then, the new data is pruned by selecting all predictors and dropping any missing values. Lastly, the predicted values for the log unit price are calculated using the model, and both the log unit price and unit price are stored in the new dataset. 8.1.5.1 Storing Predictions The resulting predictions are then stored in two ways. First, an RDS file containing the full new dataset along with two additional new columns representing the predicted log unit price and predicted unit price are created; this file is stored in the data/output/ directory. Second, an Excel file containing the item ID, the descriptions from item_solicitado, llamado_grupo, and llamado, the execution date, and predicted log unit price and unit price is created and stored in the data/output/ directory. 8.1.6 Outputs The following are the outputs produced by running predict.R. data/ output/dataset_DATE_with_predictions.rds (RDS file containing all predictors as columns as well as the predicted values for the log unit price and unit price for each row) output/dataset_DATE_with_predictions.xlsx (Excel file containing some relevant description and date predictors as columns as well as the predictions for the log unit price and unit price) 8.2 The Configuration File The configuration file predict_conf.yaml contains the inputs for the tasks outlined above. This file needs to be altered for any desired change of input, and instructions for how those alterations can be made are listed below. The application/prediction configuration file is broken down into three stages: the Data, the Features, and the Model. 8.2.1 Data To load in the correct new input data, the data$loc value should contain the directory in which the new input data files are located. The default value is data/raw/; however, to use a different data directory, the data files can simply be put into a new directory, and the path of the new directory can be listed at loc. Similarly, the dest directory should contain the directory where the user desires the outputs from predict.R to be stored. The dest directory can also be changed if the user wishes to have outputs stored somewhere other than the default directory. data: loc: &#39;data/raw/&#39; dest: &#39;data/output/&#39; Other values in the data section of the configuration files are the required input CSV files; these values should not be changed. 8.2.2 Features The features section contains the merging ID and variables to be one-hot encoded and log-transformed. The ID should not be altered; however, to add any variables to be one-hot encoded or log-transformed, simply append them to the one_hot_encoded_vars list and log_transforms list respectively while ensuring that the variable names are enclosed in single quotations as shown. features: id: &#39;item_solicitado_id&#39; # unique id one_hot_encoded_vars: [&#39;tipo_unidad_contratacion&#39;, &#39;nombre_nivel_entidad&#39;, &#39;forma_adjudicacion_llamado&#39;, &#39;forma_pago_llamado&#39;, &#39;descripcion_ingles_producto_n1&#39;] log_transforms: Also included in the features section is the extra_vars list, which contains a list of non-predictor variables in the dataset that the user wishes to see in the final output. For example, decripcion_item_solicitado is not a predictor in the model training, but contains useful information on the nature of each item; thus, it could be included in extra_vars. To add variables to extra_vars, simply append them to the list and ensure that their names are enclosed in single quotations as shown below. extra_vars: [&#39;item_solicitado_id&#39;, &#39;descripcion_item_solicitado&#39;, &#39;descripcion_llamado_grupo&#39;, &#39;descripcion_llamado&#39;, &#39;fecha_ejecucion_pac&#39;] 8.2.3 Model The model section contains the directory of the final predictive model and one-hot encoding model to be used to generate predictions on the new raw data. The predictive model’s directory and file name can be changed by writing the directory in the loc value of model and the file name in the winning_model value of model. The one-hot encoding model, which is generated by running the fe.R script, can have its directory and file name updated by changing the loc value in ohe_model to the directory the one-hot encoding model is located in and changing the last_run_date value in ohe_model to the most recent date when the fe.R script was run. model: loc: &#39;/files/&#39; # loc is input path winning_model: &#39;model_inter_final.rds&#39; ohe_model: loc: &#39;data/output/&#39; last_run_date: &#39;2021-08-11&#39; "],["eval.html", "9 Model Evaluation 9.1 Evaluation Metrics 9.2 Most Important Features 9.3 Models Used 9.4 Top 10 Most Important Features", " 9 Model Evaluation 9.1 Evaluation Metrics For this project, several evaluation criteria were used to understand model performances. 9.1.1 RMSE The root mean square error (RMSE) was used to understand the general deviance that model predictions had from their actual values. The RMSE gives an estimate of the error in guarani or USD for each item prediction. Typically, the mean is used as the basis for calculating this error; however, this caused outliers to significantly impact the RMSE values, and so the median was used as the center instead in most RMSE calculations for this project. 9.1.2 Range The range of the prediction is the difference between the maximum and minimum value in the predicted values. The range helps to understand the dispersion between models. 9.1.3 \\(R^2\\) R-squared (\\(R^2\\) is a statistical measure that represents the proportion of the variance of a dependent variable that is explained by the independent variables in a model predicting it. Using this metric, it became clear that more complex models such as XGBoost and random forests performed better with regards to \\(R^2\\). 9.1.4 MAE Mean absolute error (MAE) is a measure of errors between paired observations, calculated as the mean of the absolute values of the differences between predicted and actual values by models. It is usually similar in magnitude to RMSE, but slightly smaller, as can be seen from the results of winning model 9.2 Most Important Features Further evaluation methods were to look at the most important features from each model, as shown through the code below. 9.3 Models Used 9.3.1 Linear Regression linear regression was used to have baseline KPIs setup for the model to fit the data, as it is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Linear regression was the first type of regression analysis to be performed rigorously. This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine. The quantitative results of the linear regression model can be seen below. KPI results from the goods dataset: RMSE: 0.89274 MAE: 0.68324 R Squared: 0.35687 Non-Log RMSE: 24489313.70398 PYG (3673.39706 USD) Non-Log Median RMSE: 58995.87842 PYG (8.84938 USD) KPI results from the services dataset: RMSE: 1.05749 MAE: 0.8429 R Squared: 0.17311 Non-Log RMSE: 56371120.49851 PYG (8455.66807 USD) Non-Log Median RMSE: 350812.10185 PYG (52.62182 USD) KPI results from the combined dataset (both goods and services): RMSE: 0.99793 MAE: 0.77541 R Squared: 0.32015 Non-Log RMSE: 64734360.72949 PYG (9710.15411 USD) Non-Log Median RMSE: 201014.94886 PYG (30.15224 USD) 9.3.2 Random Forest Random forest is an ensemble machine learning method in the case of regression, which is mainly implemented by building a great number of decision trees during the training time and outputting the averaging forest’s prediction of the individual trees. The random forest in mlr3 can be tuned with several tuning parameters: number of trees to grow tree n, number of variables at each random split selection mtry, and so on. The quantitative results of the random forest model can be seen below. KPI results from the goods dataset: RMSE: 0.53668 MAE:0.39888 R Squared: 0.76758 Non-Log RMSE: 21077688.3875 PYG (3161.65326 USD) Non-Log Median RMSE: 29468.16874 PYG (4.42023 USD) KPI results from the services dataset: RMSE: 0.55089 MAE: 0.41274 R Squared: 0.7756 Non-Log RMSE: 47733933.54249 PYG (7160.09003 USD) Non-Log Median RMSE: 188064.15382 PYG (28.20962 USD) 9.3.3 XGBoost XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now. KPI results from the combined dataset (both goods and services) using the XGBoost model: RMSE: 0.48002 MAE:0.3523 R Squared: 0.8427 Non-Log RMSE: 51125287.18182 PYG (7668.79308 USD) Non-Log Median RMSE: 55966.30043 PYG (8.39495 USD) KPI results from the services dataset using the XGBoost model: RMSE: 0.48415 MAE:0.35441 R Squared: 0.82668 Non-Log RMSE: 42147072.80922 PYG (6322.06092 USD) Non-Log Median RMSE: 153284.64994 PYG (22.9927 USD) KPI results from the goods dataset using the XGBoost model: RMSE: 0.47235 MAE:0.34788 R Squared: 0.81996 Non-Log RMSE: 19324456.90415 PYG (2898.66854 USD) Non-Log Median RMSE: 24234.82391 PYG (3.63522 USD) 9.4 Top 10 Most Important Features There are two different standards to compute the influence on the model from different variables. One is computed from permuting the out-of-bag data, and another one is computed from the total decrease in node impurities. Thus, we are able to focus on less but more important variables when there are a great number of variables in the data set. A benefit of using ensembles methods like gradient boosting and random forests is that they can automatically provide estimates of feature importance from a trained predictive model. 9.4.1 Goods-Only Dataset As can be seen from the bar plot above, item cantidad plays an important role in predicting the prices, and following variables related to information technology, broadcasting telecommunication, furniture, office context, army buyer, private vehicles, and forma_adjudicacion have also an impact in prediction. 9.4.2 Services-Only Dataset From the bar plot above, item cantidad plays an important role in predicting the prices, and following variables related to fine art and graphic services, building construction and maintenance, administrative and transportation services, forma_adjudicacion and institucion have also an impact on predictions. 9.4.3 Combined Dataset As can be seen from the bar plot above, item cantidad plays an important role in predicting the prices, and variables related to building and construction services, hardware context, furniture, office context and construction context are calso onsidered important for prediction. "],["conclusions.html", "10 Conclusions 10.1 Outcomes 10.2 Limitations", " 10 Conclusions 10.1 Outcomes Using various analytical and graphical tools, we evaluated the predictive performance of multiple models applied to actual data to predict the unit price of different items, including goods and services that governments and state-owned institutions purchased in the public procurement process. In addition, our models helped identify which characteristics of the dataset were most strongly associated with unit item price and could explain most of the price variation. We then turned our attention to making our pipeline automated with our input data and input model, helping us construct an automatic process for making EDAs for new datasets, training new models, and generating predictions on new datasets. Furthermore, we improved our models’ prediction error rates by enhancing the feature engineering process using only a set of features available from approximately 3 million items over 10 years of public procurement conducted by the DNCP. We then employed clustering methods and text mining to find and evaluate new features for model prediction. The models used in this study consisted of simple linear regression, random forests, and Gradient Boosting to predict item prices. The models were compared and assessed using median root mean square error and \\(R^2\\) as performance metric criteria. Linear regression achieved the lowest median root mean square error value when accounting for goods and service items (median RMSE at $30). At the same time, the XGBoost ensemble method appeared to perform best with the predictors for the dataset consisting only of goods (median RMSE at $3), which explains most variation in unit item prices. These findings are helpful to the DNCP in analysing the distribution of items across different tenders. The results from our study can help provide answers to government and public institutions when making decisions such as how accurately the value of a tender can be assessed and what types of items should be scrutinized most when searching for anomalies in pricing. 10.2 Limitations Despite having produced a working automated pipeline that met our initial requirements for predicting unit item prices, various improvements can be made in the future. These include improvements we did not complete due to limited time on the project such as confidence intervals for more detailed anomaly detection in pricing by users and a lack of computational power to run more complex machine learning models. Most notably, however, a further segmentation of the training dataset into different categories to train multiple models may have been helpful, but was not completed due to time constraints. This may have decreased the overall percent deviation from the mean for pricing predictions. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
